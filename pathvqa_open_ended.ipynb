{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import time\n",
    "import pathlib\n",
    "from utils.load_data import DataLoader\n",
    "from utils.evaluation import AnswerEvaluator\n",
    "from utils.training_toolkit import CustomSchedule, loss_function\n",
    "from models.Transformer.transformers import VQATransformer\n",
    "from models.Transformer.masks import create_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers=3\n",
    "d_model=512\n",
    "num_heads=8\n",
    "dff=2048\n",
    "maximum_position_encoding=10000\n",
    "EPOCHS = 20\n",
    "batch_size = 64\n",
    "cnn_type = 'resnet'\n",
    "embedding = 'bioelmo'  # choose from ['w2v', 'bioelmo', 'biobert', 'bluebert', 'large_biobert', 'elmo']\n",
    "data_augmentation = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### DO NOT CHANGE VALUES OF THIS BLOCK IF YOU ARE NOT THE DEVELOPER ##########\n",
    "\n",
    "check_point_path = './check_point/transformer/open_ended/' + embedding +'/' + cnn_type + '_' + str(num_layers)\n",
    "saving_folder = './open_ended_results/transformer/' + embedding + '/'\n",
    "save_result_path = saving_folder + cnn_type + '_' + str(num_layers) + '.csv'\n",
    "\n",
    "emb_size = 1024\n",
    "pe_output = 36 + 1\n",
    "MAX_LENGTH = pe_output\n",
    "if cnn_type == 'inception':\n",
    "    img_shape = [299, 299]\n",
    "    img_padding = tf.TensorShape([299, 299, 3])\n",
    "if cnn_type in ['resnet', 'resnet_v2', 'dense_net', 'vgg19']:\n",
    "    img_shape = None\n",
    "    img_padding = tf.TensorShape([224, 224, 3])\n",
    "\n",
    "if embedding == 'bioelmo':\n",
    "    pe_input = 38\n",
    "elif embedding == 'elmo':\n",
    "    pe_input = 42\n",
    "elif embedding == 'biobert':\n",
    "    pe_input = 72\n",
    "    emb_size = 768\n",
    "elif embedding == 'bluebert':\n",
    "    pe_input = 69\n",
    "elif embedding == 'large_biobert':\n",
    "    pe_input = 60  \n",
    "elif embedding == 'w2v':\n",
    "    pe_input = 48\n",
    "    emb_size = 200\n",
    "elif embedding == 'bert':\n",
    "    pe_input = 72\n",
    "    emb_size = 1024\n",
    "else:\n",
    "    raise TypeError(\"Wrong embedding type\")\n",
    "    \n",
    "if data_augmentation:\n",
    "    aug = tf.keras.Sequential([tf.keras.layers.experimental.preprocessing.RandomFlip(),\n",
    "                               tf.keras.layers.experimental.preprocessing.RandomRotation(0.05)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train, val, test dataset\n",
    "data_loader = DataLoader('./data', emb_folder=embedding)\n",
    "full_dataset, tokenizer = data_loader.create_dataset('open_ended')\n",
    "vocab_size=len(tokenizer.index_word) + 1\n",
    "Data_SET_SIZE = len(full_dataset)\n",
    "train_size = int(0.52 * Data_SET_SIZE)\n",
    "val_size = int(0.30 * Data_SET_SIZE)\n",
    "test_size = int(0.18 * Data_SET_SIZE)\n",
    "train_set = full_dataset.take(train_size)\n",
    "val_test_ds = full_dataset.skip(train_size)\n",
    "val_set = val_test_ds.take(val_size)\n",
    "test_ds = val_test_ds.skip(val_size)\n",
    "test_set = test_ds.take(test_size)\n",
    "\n",
    "batch_train_set = train_set.padded_batch(batch_size, padded_shapes=((img_padding, tf.TensorShape([pe_input, emb_size])),\n",
    "                                                                    tf.TensorShape([pe_output-1]), []), drop_remainder=True)\n",
    "batch_test_set = test_set.padded_batch(1, padded_shapes=((img_padding, tf.TensorShape([pe_input, emb_size])),\n",
    "                                                         tf.TensorShape([pe_output-1]), []), drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Models and Related Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = VQATransformer(num_layers, d_model, num_heads, dff, vocab_size, pe_input, pe_output,\n",
    "                          pretrained_cnn_type=cnn_type)\n",
    "\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, check_point_path, max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(img, question, tar):\n",
    "    if data_augmentation:\n",
    "        img = aug(img)\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(question, tar_inp)\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(question, img, tar_inp,\n",
    "                                     True,\n",
    "                                     enc_padding_mask,\n",
    "                                     combined_mask,\n",
    "                                     dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(question, img):\n",
    "    end_token = tf.constant(tokenizer.texts_to_sequences(['<end>']), tf.int32)\n",
    "    output = dec_input = tf.expand_dims([tokenizer.word_index['<start>']], 0)\n",
    "    for i in range(MAX_LENGTH):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            question, output)\n",
    "        predictions, attention_weights = transformer(question,\n",
    "                                                     img,\n",
    "                                                     output,\n",
    "                                                     False,\n",
    "                                                     enc_padding_mask,\n",
    "                                                     combined_mask,\n",
    "                                                     dec_padding_mask)\n",
    "\n",
    "        predictions = predictions[:, -1:, :]\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "        if predicted_id == end_token:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "    return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## restore check point \n",
    "# ckpt.restore(ckpt_manager.latest_checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.9047 Accuracy 0.0000\n",
      "Epoch 1 Batch 50 Loss 0.7521 Accuracy 0.0187\n",
      "Epoch 1 Batch 100 Loss 0.7009 Accuracy 0.0236\n",
      "Epoch 1 Loss 0.6853 Accuracy 0.0248\n",
      "Time taken for 1 epoch: 52.57703709602356 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.6601 Accuracy 0.0286\n",
      "Epoch 2 Batch 50 Loss 0.5704 Accuracy 0.0290\n",
      "Epoch 2 Batch 100 Loss 0.5555 Accuracy 0.0302\n",
      "Saving checkpoint for epoch 2 at ./check_point/transformer/open_ended/bioelmo/resnet_3\\ckpt-1\n",
      "Epoch 2 Loss 0.5497 Accuracy 0.0308\n",
      "Time taken for 1 epoch: 41.56041407585144 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.5671 Accuracy 0.0321\n",
      "Epoch 3 Batch 50 Loss 0.4829 Accuracy 0.0343\n",
      "Epoch 3 Batch 100 Loss 0.4751 Accuracy 0.0356\n",
      "Epoch 3 Loss 0.4737 Accuracy 0.0362\n",
      "Time taken for 1 epoch: 40.27116656303406 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.5153 Accuracy 0.0357\n",
      "Epoch 4 Batch 50 Loss 0.4284 Accuracy 0.0386\n",
      "Epoch 4 Batch 100 Loss 0.4221 Accuracy 0.0400\n",
      "Saving checkpoint for epoch 4 at ./check_point/transformer/open_ended/bioelmo/resnet_3\\ckpt-2\n",
      "Epoch 4 Loss 0.4216 Accuracy 0.0405\n",
      "Time taken for 1 epoch: 42.43341684341431 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.4625 Accuracy 0.0375\n",
      "Epoch 5 Batch 50 Loss 0.3829 Accuracy 0.0431\n",
      "Epoch 5 Batch 100 Loss 0.3774 Accuracy 0.0442\n",
      "Epoch 5 Loss 0.3774 Accuracy 0.0447\n",
      "Time taken for 1 epoch: 40.41747570037842 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.4162 Accuracy 0.0446\n",
      "Epoch 6 Batch 50 Loss 0.3441 Accuracy 0.0471\n",
      "Epoch 6 Batch 100 Loss 0.3386 Accuracy 0.0483\n",
      "Saving checkpoint for epoch 6 at ./check_point/transformer/open_ended/bioelmo/resnet_3\\ckpt-3\n",
      "Epoch 6 Loss 0.3390 Accuracy 0.0486\n",
      "Time taken for 1 epoch: 41.819419384002686 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.3841 Accuracy 0.0482\n",
      "Epoch 7 Batch 50 Loss 0.3126 Accuracy 0.0500\n",
      "Epoch 7 Batch 100 Loss 0.3066 Accuracy 0.0512\n",
      "Epoch 7 Loss 0.3071 Accuracy 0.0516\n",
      "Time taken for 1 epoch: 40.45647859573364 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.3611 Accuracy 0.0473\n",
      "Epoch 8 Batch 50 Loss 0.2828 Accuracy 0.0533\n",
      "Epoch 8 Batch 100 Loss 0.2762 Accuracy 0.0548\n",
      "Saving checkpoint for epoch 8 at ./check_point/transformer/open_ended/bioelmo/resnet_3\\ckpt-4\n",
      "Epoch 8 Loss 0.2758 Accuracy 0.0553\n",
      "Time taken for 1 epoch: 42.22506833076477 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.3291 Accuracy 0.0509\n",
      "Epoch 9 Batch 50 Loss 0.2518 Accuracy 0.0570\n",
      "Epoch 9 Batch 100 Loss 0.2470 Accuracy 0.0584\n",
      "Epoch 9 Loss 0.2472 Accuracy 0.0588\n",
      "Time taken for 1 epoch: 40.48879361152649 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.3065 Accuracy 0.0549\n",
      "Epoch 10 Batch 50 Loss 0.2266 Accuracy 0.0597\n",
      "Epoch 10 Batch 100 Loss 0.2220 Accuracy 0.0613\n",
      "Saving checkpoint for epoch 10 at ./check_point/transformer/open_ended/bioelmo/resnet_3\\ckpt-5\n",
      "Epoch 10 Loss 0.2218 Accuracy 0.0619\n",
      "Time taken for 1 epoch: 42.01487326622009 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.2735 Accuracy 0.0607\n",
      "Epoch 11 Batch 50 Loss 0.2008 Accuracy 0.0641\n",
      "Epoch 11 Batch 100 Loss 0.1971 Accuracy 0.0651\n",
      "Epoch 11 Loss 0.1975 Accuracy 0.0656\n",
      "Time taken for 1 epoch: 40.530198097229004 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.2314 Accuracy 0.0647\n",
      "Epoch 12 Batch 50 Loss 0.1761 Accuracy 0.0679\n",
      "Epoch 12 Batch 100 Loss 0.1730 Accuracy 0.0688\n",
      "Saving checkpoint for epoch 12 at ./check_point/transformer/open_ended/bioelmo/resnet_3\\ckpt-6\n",
      "Epoch 12 Loss 0.1729 Accuracy 0.0695\n",
      "Time taken for 1 epoch: 42.332629919052124 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.2105 Accuracy 0.0683\n",
      "Epoch 13 Batch 50 Loss 0.1546 Accuracy 0.0709\n",
      "Epoch 13 Batch 100 Loss 0.1527 Accuracy 0.0719\n",
      "Epoch 13 Loss 0.1514 Accuracy 0.0727\n",
      "Time taken for 1 epoch: 40.58189344406128 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.1785 Accuracy 0.0768\n",
      "Epoch 14 Batch 50 Loss 0.1341 Accuracy 0.0743\n",
      "Epoch 14 Batch 100 Loss 0.1310 Accuracy 0.0756\n",
      "Saving checkpoint for epoch 14 at ./check_point/transformer/open_ended/bioelmo/resnet_3\\ckpt-7\n",
      "Epoch 14 Loss 0.1300 Accuracy 0.0765\n",
      "Time taken for 1 epoch: 42.620084047317505 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.1649 Accuracy 0.0754\n",
      "Epoch 15 Batch 50 Loss 0.1183 Accuracy 0.0769\n",
      "Epoch 15 Batch 100 Loss 0.1155 Accuracy 0.0782\n",
      "Epoch 15 Loss 0.1138 Accuracy 0.0792\n",
      "Time taken for 1 epoch: 40.47517275810242 secs\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.1551 Accuracy 0.0732\n",
      "Epoch 16 Batch 50 Loss 0.1022 Accuracy 0.0797\n",
      "Epoch 16 Batch 100 Loss 0.0998 Accuracy 0.0809\n",
      "Saving checkpoint for epoch 16 at ./check_point/transformer/open_ended/bioelmo/resnet_3\\ckpt-8\n",
      "Epoch 16 Loss 0.0989 Accuracy 0.0818\n",
      "Time taken for 1 epoch: 43.22227764129639 secs\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.1383 Accuracy 0.0804\n",
      "Epoch 17 Batch 50 Loss 0.0872 Accuracy 0.0824\n",
      "Epoch 17 Batch 100 Loss 0.0856 Accuracy 0.0833\n",
      "Epoch 17 Loss 0.0846 Accuracy 0.0842\n",
      "Time taken for 1 epoch: 40.70871686935425 secs\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.1022 Accuracy 0.0817\n",
      "Epoch 18 Batch 50 Loss 0.0772 Accuracy 0.0841\n",
      "Epoch 18 Batch 100 Loss 0.0772 Accuracy 0.0849\n",
      "Saving checkpoint for epoch 18 at ./check_point/transformer/open_ended/bioelmo/resnet_3\\ckpt-9\n",
      "Epoch 18 Loss 0.0765 Accuracy 0.0858\n",
      "Time taken for 1 epoch: 42.59805989265442 secs\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.0958 Accuracy 0.0879\n",
      "Epoch 19 Batch 50 Loss 0.0683 Accuracy 0.0856\n",
      "Epoch 19 Batch 100 Loss 0.0680 Accuracy 0.0865\n",
      "Epoch 19 Loss 0.0683 Accuracy 0.0870\n",
      "Time taken for 1 epoch: 40.282779932022095 secs\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.0822 Accuracy 0.0911\n",
      "Epoch 20 Batch 50 Loss 0.0622 Accuracy 0.0869\n",
      "Epoch 20 Batch 100 Loss 0.0617 Accuracy 0.0877\n",
      "Saving checkpoint for epoch 20 at ./check_point/transformer/open_ended/bioelmo/resnet_3\\ckpt-10\n",
      "Epoch 20 Loss 0.0616 Accuracy 0.0884\n",
      "Time taken for 1 epoch: 42.13184309005737 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    for (batch, (img_question, tar, _)) in enumerate(batch_train_set):\n",
    "        train_step(img_question[0], img_question[1], tar)\n",
    "        if batch % 50 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "                epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                            ckpt_save_path))\n",
    "\n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1,\n",
    "                                                train_loss.result(),\n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting and Evaluating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting...\n",
      "predicted answer: 2956\r"
     ]
    }
   ],
   "source": [
    "true_answers_list = []\n",
    "predicted_answers_list = []\n",
    "ques_id_list = []\n",
    "print('Start predicting...')\n",
    "for (batch, (img_question, target, ques_id)) in enumerate(batch_test_set):\n",
    "    target = target.numpy()\n",
    "    target = target[0]\n",
    "    true_answer = []\n",
    "    for i in target:\n",
    "        if i == 0:\n",
    "            break\n",
    "        else:\n",
    "            true_answer.append(tokenizer.index_word[i])\n",
    "    true_answer = \" \".join(true_answer[1: -1])\n",
    "\n",
    "    prediction, attention = evaluate(img_question[1], img_question[0])\n",
    "    p = prediction.numpy()\n",
    "    predict_answer = [tokenizer.index_word[i] for i in p][1:]\n",
    "    predict_answer = \" \".join(predict_answer)\n",
    "    true_answers_list.append(true_answer)\n",
    "    predicted_answers_list.append(predict_answer)\n",
    "    ques_id_list.append(ques_id)\n",
    "    print(\"predicted answer: \" + str(batch), end='\\r', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete writing ./open_ended_results/transformer/bioelmo/resnet_3.csv\n"
     ]
    }
   ],
   "source": [
    "data = {\"true answer\": true_answers_list, \"predicted answer\": predicted_answers_list, \"ques_id\": ques_id_list}\n",
    "df = pd.DataFrame(data)\n",
    "if not pathlib.Path(saving_folder).exists():\n",
    "    pathlib.Path(saving_folder).mkdir(parents=True, exist_ok=True)\n",
    "name = save_result_path\n",
    "df.to_csv(name)\n",
    "print(\"complete writing\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 34.64\n",
      "Exact Match: 23.67\n",
      "F1 Score: 34.18\n",
      "BLEU-1: 43.83\n",
      "BLEU-2: 28.53\n",
      "BLEU-3: 19.7\n",
      "BLEU-4: 11.45\n"
     ]
    }
   ],
   "source": [
    "scores = AnswerEvaluator(name).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
